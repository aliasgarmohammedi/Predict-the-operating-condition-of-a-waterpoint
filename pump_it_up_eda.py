# -*- coding: utf-8 -*-
"""Pump It Up EDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p7Z2zOGi52PAhMADnFk4WvNMEO5zkWq3

# Exploratory Data Analysis

## Data Summary
"""

from google.colab import drive
drive.mount('/content/drive/')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My Drive/Pump/

import pandas as pd
import numpy as np

df_train = pd.read_csv('Training Set.csv')

df_train.shape

"""For each water pump we were provided with 39 attributes (excluding a unique record identifier) that could potentially be used as predictor variables."""

df_labels = pd.read_csv('Training Set Labels.csv')

df_labels.head(5)

"""The Labels dataset contains the status of every Pump Observatin in the training dataset."""

df_labels.value_counts('status_group')

"""54.3% of all pumps in the data set were found to be functional, while 38.4% were non functional and 7.3% had a status of functional needs repair."""

df_train.columns

df_train.dtypes

#Merging labels and training feature
df_final = pd.merge(df_train, df_labels, on='id')

df_final.head()

"""Each independent variable can be characterized as belonging to one of three classes: non- categorical numeric variables; categorical variables; and administrative variables. Variables classified as “Administrative” in nature appear to serve solely as data management attributes within the data set.

Administrative Variables-

1.   **id**- Unique ID for each data record
2.   **date_recorded**- Date of data collection by survey company
3.   **recorded_by**- 	Name of the data collection / survey company

## Analysis of Missing Data Values
"""

0 in df_train.values

df_train.describe()

numerical_variables = ['amount_tsh','gps_height','population','longitude','latitude','num_private','construction_year']

for x in numerical_variables:
  count = (df_train[x] == 0).sum()
  print(f'Count of zeros in {x} : ', count)

"""Our analysis found that every non-categorical numeric variable contains what appear to be significant quantities of invalid data values represented by zeroes"""

#https://stackoverflow.com/questions/26266362/how-do-i-count-the-nan-values-in-a-column-in-pandas-dataframe
def missing_values_table(df):
    mis_val = df.isnull().sum()
    mis_val_percent = 100 * df.isnull().sum() / len(df)
    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)
    mis_val_table_ren_columns = mis_val_table.rename(
    columns = {0 : 'Missing Values', 1 : '% of Total Values'})
    mis_val_table_ren_columns = mis_val_table_ren_columns[
        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(
    '% of Total Values', ascending=False).round(1)
    print ("Your selected dataframe has " + str(df.shape[1]) + " columns.\n"      
        "There are " + str(mis_val_table_ren_columns.shape[0]) +
            " columns that have missing values.")
    return mis_val_table_ren_columns

missing_values_table(df_train)

"""Eight categorical variables were also found to have missing data values as indicated by ‘NAN’ values

Key data insights found:

1.   Missing data values are found within 31,587 of the 59,400 records within the data set (53.17%).
2.   3655 of the missing funder and installer values coincide with each other.
3. A pump with a total static head value of zero would not be particularly useful since it would not be capable of producing water from a source located below its output point.

The widespread incidence of missing data throughout the data set was a strong indicator of the need for the development of statistically valid data imputation algorithms for many of the affected variables.

## Insights Gained via Data Aggregation
"""

df_train.groupby(["extraction_type",'extraction_type_group'])["extraction_type_group"].count()

df_train.groupby(["extraction_type_class",'extraction_type_group'])["extraction_type_group"].count()

df_train.groupby(["payment_type",'payment'])["payment_type"].count()

df_train.groupby(["quality_group",'water_quality'])["quality_group"].count()

df_train.groupby(["quantity_group",'quantity_group'])["quantity_group"].count()

df_train.groupby(["source_type",'source'])["source"].count()

df_train.groupby(["waterpoint_type_group",'waterpoint_type'])["waterpoint_type_group"].count()

"""Several variables contained within the data set are either duplicative or composites of other variables:

1. extraction_type_group is a binned / composite version of extraction_type
2. payment_type is 100% duplicative of payment
3. quality_group is a binned / composite version of water_quality
4. quantity_group is 100% duplicative of quantity
5. source_type is a binned / composite version of source
6. waterpoint_type_group is a binned / composite version of waterpoint_type

Insights such as these serve as the basis of both the data imputation and model building efforts described herein. We can drop some of these variabled as they dont add any further value other than duplication of data.

## Data Exploration And Visualization
"""

import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

"""###Count number of pumps for each pump’s status value"""

sns.countplot(df_labels['status_group'])

"""The plot tells us that 54.3% of all pumps are functional, 38.4% are non-functional, and 7.3% are functional but in need of repair.

As we analyze each variable value, we can determine whether or not the percentage of pumps pertaining to that variable value either exceeds or falls short of the overall performance metrics plotted above. For example, those exceeding the 54.3% “functional” metric may share characteristics that poorer performing pumps may benefit from replicating.

### Data Visualization using TSNE
"""

from sklearn_pandas import DataFrameMapper
from sklearn.preprocessing import normalize
x = df_train[['amount_tsh','gps_height','num_private','population','longitude','latitude']]

import pandas as pd
from sklearn import preprocessing

x1 = x.values #returns a numpy array
min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x1)
df = pd.DataFrame(x_scaled)

df.head()

from sklearn.manifold import TSNE
from numpy import reshape
import seaborn as sns
import pandas as pd


#x = df_train[['amount_tsh','gps_height','num_private','population','longitude','latitude']]
X = df
y = df_labels['status_group']

tsne = TSNE(n_components=2,perplexity=10, verbose=1, random_state=123)
z = tsne.fit_transform(X)
df = pd.DataFrame()
df["y"] = y
df["comp-1"] = z[:,0]
df["comp-2"] = z[:,1]

sns.scatterplot(x="comp-1", y="comp-2", hue=df.y.tolist(),
                palette=sns.color_palette("hls", 3),
                data=df).set(title="Pump data T-SNE projection")

"""Only thing we can depict from the plot is that there are clusers of red points and green points whereas blue points are randomly seperated.

### Exploration of Numeric Variables

#### amount_tsh

The amount_tsh variable can be characterized as representing the “Total static head (amount water available to waterpoint)”
"""

sns.boxplot(x=df_train['amount_tsh'])

"""Boxplot for the amount_tsh variable indicate a heavily right-skewed distribution."""

df_train[df_train['amount_tsh']>0].shape[0]

"""Out of total 59400 data points only 17761 have tsh value greater than 1 which is very hard to believe as the pumps cannot have less than 1 tsh.
Perhaps the pumps located within those areas were not actually visited by the surveying company that compiled the data. Alternatively, the total static head for many pumps may simply not be known if it was not recorded when the pump was originally installed.

A pump with a total static head value of zero would not be particularly useful since it would not be capable of producing water from a source located below its output point.
"""

x = df_train[df_train['amount_tsh']>0]
y = x[x['amount_tsh']<=1000]

"""Analysis shows that 14,771 i.e most of the non-zero values fall within the range of (1 : 1000)."""

sns.histplot(data=y, x="amount_tsh", legend=True).set(title='amount_tsh value ranging from 1 to 1000')

df_tsh = df_final[['id','amount_tsh','status_group']]

r = df_tsh[(df_tsh['amount_tsh']>0) & ((df_tsh['amount_tsh']<10000))]

sns.histplot(data=r, x="amount_tsh",binwidth=200, hue="status_group", multiple="stack")

import matplotlib.pyplot as plt

for i in ['functional', 'functional needs repair', 'non functional']: 
  z=df_tsh[df_tsh['status_group']==i]
  a = z[(z['amount_tsh']>0) & ((z['amount_tsh']<10000))]
  sns.histplot(data=a, x="amount_tsh",binwidth=200,legend=True).set(title=f'amount_tsh value ranging from 1 to 10000 for {i}')
  plt.figure()

"""This leaves slightly less than 3,000 records having amount_tsh values that exceed 1000. Such values should be investigated to determine whether they are in fact valid values for the variable. Of those 3000 records, 2,810 are found to lie within the range of (1000:10,000)

Barplots for amount_tsh values suggest that pumps with relatively larger values may be more likely to be functional than are pumps having smaller values. However, since the larger values might possibly be outliers and we lack valid amount_tsh values for more than 70% of the records within the data set, it seems highly unlikely that we can derive any valid predictive inferences from the plots.

#### gps_height

The gps_height variable represents the physical altitude of a pump
"""

sns.boxplot(x=df_train['gps_height'])

"""Plots for the gps_height variable indicate a heavily right-skewed distribution"""

sns.histplot(data=df_train, x="gps_height", legend=True).set(title='gps_height Histogram')

df_train[df_train['gps_height']<0].count()[0]

df_train[df_train['gps_height']==0].count()[0]

df_temp = df_train[df_train['gps_height']==0]
df_temp[(df_temp['latitude']>-1) & (df_temp['longitude']==0)].count()[0]

"""The boxplot and histogram show that a portion of the data records contain a negative gps_height value. An analysis of the variable finds 1,496 such records within the data set.

While it may be somewhat surprising to have a pump located below sea level, Africa is in fact home to many areas where the actual land altitude falls below sea level. As such, further investigation is required to determine whether or not these negative values are valid within the context of the data set.

The histogram shown above indicates that the majority of non-zero and non-negative gps_height values lie in the range of (1000:2000). The histogram also indicates the presence of a significant number of zero values for the variable. Further analysis finds a total of 20,438 data records containing a zero value for the gps_height variable.

The fact that those zero values coincide with missing latitude and longitude coordinates stongly suggests that they are also representative of missing data.

"""

df_gps = df_final[['id','gps_height','status_group']]

sns.histplot(data=df_gps, x="gps_height", hue="status_group", multiple="stack")

import matplotlib.pyplot as plt

for i in ['functional', 'functional needs repair', 'non functional']:  
  z=df_gps[df_gps['status_group']==i]
  a = z[z['gps_height']>0]
  sns.histplot(data=a, x="gps_height",binwidth=200, legend=True).set(title=f'gps_height values for {i}')
  plt.figure()

"""Barplots for the non-zero gps_height values show that pumps located at relatively higher altitudes are more likely to be functional than are pumps found at lower altitudes. However, pumps located at altitudes higher than agps_height value of approximately 2500 are also the most likely to be functional needs repair, followed by those lying within the approximate range of (1000:1600). We also find that pumps located at relatively low altitudes (i.e., between 0 and 800) are the most likely to be non-functional.

#### population

The population variable represents the human population in the area surrounding a pump.
"""

sns.boxplot(x=df_train['population'])

"""Most of the population is saturated within 10000 and only few cases of above. It can be considered as exceptions or outliers."""

sns.histplot(data=df_train, x="population",binwidth=100,binrange=(0,3000), legend=True).set(title='Population Histogram')

"""Plot suggest that the vast majority of the pumps are located in the vicinity of small villages comprised of less than 500 inhabitants. This suggests that it may be feasible to impute the missing population values for predictive modeling purposes via use of the median. 

However, such an approach may have an adverse effect on the distribution of the variable.
"""

df_train[df_train['population']==0].count()[0]

"""Our analysis indicates the presence of 21,381 data records containing a zero value for the population variable.

While it may in fact be realistic to find a pump located in an unpopulated area, it seems highly unlikely that such a large number of pumps would reside in locations that are devoid of human inhabitants. As such, many of these zero values are likely to be invalid.
"""

df_train[df_train['population']>0]['population'].median()

df_train[df_train['population']>0]['population'].max()

"""Analysis of the non-zero population figures reveals a highly right-skewed distribution, with a median value of 150 and a maximum value of 30,500."""

df_train.groupby(['amount_tsh','population','gps_height','subvillage'])['subvillage'].count()

"""As with the amount_tsh, population and gps_height variables, we find a significant amount of clustering relative to the **geographic variables** for e.g. subvillage.

The lack of accurate data values across so many geographic indicators strongly suggests that imputing the missing data values via geographic indicators will not be possible.
"""

df_pop_temp = df_final[(df_final['population']>0) & (df_final['population']<1000)]

sns.histplot(data=df_pop_temp, x="population", hue="status_group",binwidth=50,binrange=(0,1000), multiple="stack")

import matplotlib.pyplot as plt

for i in ['functional', 'functional needs repair', 'non functional']:  
  z=df_final[df_final['status_group']==i]
  df_pop_temp = z[(z['population']>0) & (z['population']<1000)]
  sns.histplot(data=df_pop_temp, x="population",binwidth=50,binrange=(0,1000), legend=True).set(title=f'population values for {i}')
  plt.figure()

"""Barplots for the non-zero population values of less than 1000 show no obvious relationship between population and the likelihood of a pump being functional. However, pumps located in areas with relatively larger populations do appear to be somewhat more likely to have a status of functional needs repair than are pumps located in less densely populated areas. Finally, pumps located in relatively higher population areas appear to be somewhat less likely to be non functional than are pumps located in areas with relatively smaller populations.

#### Longitude & Latitude

Longitude and latitude coordinates are provided for each pump within the data set. 
Summary statistics and plots indicate that at least a portion of the coordinates provided may be invalid, as indicated by the zero and near-zero values found in the both variables.
"""

sns.boxplot(x=df_train['longitude'])

sns.histplot(data=df_train, x="longitude",binwidth=2,binrange=(0,44), legend=True).set(title='Longitude Histogram')

sns.boxplot(x=df_train['latitude'])

sns.histplot(data=df_train, x="latitude",binwidth=1, legend=True).set(title='latitude Histogram')

df_train[df_train['latitude']>-1].count()[0]

df_train[df_train['longitude']==0].count()[0]

"""Further analysis finds 1812 zero values within the longitude variable and 1819 values less than -1 for the latitude variable."""

df_train.groupby(['latitude','longitude'])['latitude'].count()

"""A cross referencing of the two variables shows that every instance of a zero longitude value does in fact correspond with an instance of a (< -1) latitude value. 
We have 1812 such instances.

The fact that these values appear to be coincident strongly suggests that they are simply invalid data values.

Given the relatively small number of invalid longitude and latitude values present within the data set, a reasonable approach to their imputation could be based on calculating the mean or median longitude and latitude values for a data record’s ward or region and using those values as the imputed values for the missing data.
"""

df_long_temp = df_final[df_final['longitude']>0]
df_lat_temp = df_final[df_final['latitude']<-1]

sns.histplot(data=df_long_temp, x="longitude", hue="status_group",binwidth=1, multiple="stack")

"""Barplots for the non-zero longitude values indicate that pumps located between 34 and 38 degrees longitude are more likley to be functional than are pumps at other longitudes, while those located between 30 and 31 degrees longitude are much more likely to have a status of functional needs repair than are pumps located at other longitudes. 

Finally, we see that longitude can be somewhat indicative of how likely a pump is to be non functional. Therefore, the longitude variable appears to offer a fair amount of predictive value.
"""

sns.histplot(data=df_lat_temp, x="latitude", hue="status_group",binwidth=0.3, multiple="stack")

"""Barplots for latitude values of less than (-1) indicate that pumps at some latitudes are much more likely to be either functional or functional needs repair than are pumps at other latitudes. Therefore, the latitude variable appears to offer a fair amount of predictive value.

#### num_private

No clear explanation is provided regarding what the num_private variable is meant to represent. Summary statistics and plots show a heavily right-skewed distribution with zero values dominating the variable throughout the data set.
"""

sns.boxplot(x=df_train['num_private'])

sns.histplot(data=df_train, x="num_private", legend=True).set(title='num_private Histogram')

df_train[df_train['num_private']==0].count()[0]

df_train[df_train['num_private']>0].count()[0]

sns.histplot(data=df_final, x="num_private", hue="status_group",binrange=(0,10), multiple="stack")

"""In fact, analysis reveals that only 757 of the data set’s 59,400 num_private values are non-zero.

Unfortunately, the lack of an explanation of the meaning of the variable means we have no way of knowing whether the large number of zero values represent legitimate data values or simply serve as an indicator of missing data.
"""

len(list(df_train['num_private'].unique()))

"""The variable is comprised of a total of 65 distinct values.

### Exploration of Categorical Variables

#### funder

The funder variable represents the name of the organization that funded the installation of a given pump.
"""

len(list(df_train['funder'].unique()))

"""A total of 1,898 distinct values for the variable are found within the data set, along with 3,635 missing values."""

#The top 20 funders by pump count are shown in the table below:
df_funder=df_train.groupby(['funder']).count()
df_funder['id'].sort_values(ascending=False).head(20)



"""In the table above we note the presence of “Government of Tanzania”, “Ministry of Water”, and “Water”. It is quite possible that each of these values refer to the Tanzanian government. Such inconsistency may be unnecessarily increasing the number of distinct funder values while simultaneously dilluting the accuracy of the data records.

#### installer

The installer variable represents the name of the organization that installed a given pump.
"""

len(list(df_train['installer'].unique()))

"""A total of 2,146 distinct values for the variable are found within the data set, along with 3,655 missing values."""

#The top 20 installers by pump count are shown in the table below:
df_funder=df_train.groupby(['installer']).count()
df_funder['id'].sort_values(ascending=False).head(20)

"""In the table above we note the presence of "Government" and "Central Government", as well as both "Commu" and "Community". It is quite possible that each of these pairs values refer to a single installer.

#### Funder & Installer: Overlap of Missing Values
"""

df_train[df_train['funder'].isnull()].count()[0]

df1=df_train[df_train['funder'].isnull()]
df2=df1[['funder','installer']]
df2.head()

non_nan_values_in_installer=df2.count()[1]
non_nan_values_in_installer
total_nan_values_in_installer = 3635 - non_nan_values_in_installer
total_nan_values_in_installer

"""A cursory review of the data set indicates that many instances of missing data within the funder variable are coincident with missing values for the installer variable. In fact, we find that 3,582 of the 3,635 instances of funder = NA occur when the installer variable is also unknown.

#### wpt_name

The wpt_name variable represents a name that has been assigned to given waterpoint.
"""

len(list(df_train['wpt_name'].unique()))

"""A total of 37,400 distinct values for the variable are found within the data set, along with 3,563 instances where no defined name could be identified.

Given the large number of possible wpt_name values as a proportion of the total records contained within the data set (37400 / 59400), the wpt_name variable likely offers limited, if any, value for predictive modeling purposes.

#### basin

The basin variable represents the name of the geographic water basin within which a given pump is located.
"""

len(list(df_train['basin'].unique()))

"""The summary statistics shown below indicate a total of 9 distinct water basins within the data set, with each record having a valid value."""

df_basin = df_final[['basin','status_group']]
df_basin.groupby(['basin','status_group'])['basin'].count()

plt.figure(figsize=(15,6)) 
sns.histplot(data=df_basin, x="basin", hue="status_group", multiple="stack")

"""Plots for the basin variable show a wide variance in the proportions of functional pumps between basins: Three (Lake Nyasa, Pangani, Rufiji) have more than 60% of their pumps functioning while the Southern Coast basin has only 37.2% of its pumps functioning. In fact, five of the nine basins fail to achieve the overall “functional” metric of 54.3%.

#### Subvillage

The subvillage variable represents the name of the geographic subvillage within which a given pump is located.
"""

len(list(df_train['subvillage'].unique()))

df_train[df_train['subvillage'].isnull()].count()[1]

"""Summary statistics indicate a total of 19,288 distinct subvillage values within the data set, with 371 missing values.

Given the large number of possible subvillage values as a proportion of the total records contained within the data set (19288 / 59400), the variable may offer limited value for predictive modeling purposes.
"""

#The top 10 subvillage by pump count are shown in the table below:
df_sub=df_train.groupby(['subvillage']).count()
df_sub['id'].sort_values(ascending=False).head(10)

"""#### Region

The region variable represents the name of the geographic region in Tanzania within which a given pump is located.
"""

len(list(df_train['region'].unique()))

"""The summary statistics shown below indicate a total of 21 distinct regions within the data set, with each record having a valid value."""

#The top 10 region by pump count are shown in the table below:
df_reg=df_train.groupby(['region']).count()
df_reg['id'].sort_values(ascending=False).head(10)

plt.figure(figsize=(20,6)) 
sns.histplot(data=df_final, x="region", hue="status_group", multiple="stack")

"""The functional pump disparities found within the various regions exceed those seen within the basin variable: we see one region (Iringa) having more than 78.2% of its pumps functional while the region of Lindi has only 29.8% functional, a nearly 50 point difference. In fact, of the 21 regions listed, only 9 exceed the overall functional metric of 54.3%. Furthermore, we find the region of Kigoma has 21.4% of its pumps as “functional needs repair”, a percentage that greatly exceeds all other regions.


"""

df_unique = df_final[['amount_tsh','gps_height','construction_year','num_private','population','region']]

df_unique[df_unique['region']=='Dodoma'].count()

df_unique[df_unique['region']=='Dodoma'].isnull().count()

"""Analysis of individual regions reveals that the four specific regions are found to have zero values for the following variables:

1. amount_tsh
2. gps_height
3. construction_year
4. num_private
5. population

The four regions are:

- Dodoma
- Kagera
- Mbeya
- Tabora

The lack of non-zero values throughout the four indicated regions for the five variables listed above makes it highly unlikely that we will be able to effectively derive imputed values for the zero values of those five variables using the geographical indicators provided within the data set.

#### Region Code

The region_code variable provides an integer code for the Tanzanian region within which a given pump is located.
"""

len(list(df_train['region_code'].unique()))

"""The summary statistics shown below indicate a total of 27 distinct region codes within the data set, with each record having a valid value.

It is unclear why we find 27 region_code values while there are only 20 possible values for the region variable.
"""

#The top 10 region code by pump count are shown in the table below:
df_reg_c=df_train.groupby(['region_code']).count()
df_reg_c['id'].sort_values(ascending=False).head(10)

plt.figure(figsize=(20,6)) 
sns.histplot(data=df_final, x="region_code", hue="status_group",binwidth=1, multiple="stack")

"""Plotting the status of pumps relative to each value of the region_code variable shows even greater disparities between geographic regions for functional pumps, from a low of 8.7% in Region 8 to nearly 97% in Region 24. Region 16 shows an unusually large 21.4% of its pumps having a status of “functional needs repair” while Region 40’s single pump (100% of the pumps in that region) is not functioning.

#### Construction Year

The construction_year variable indicates the year in which a given pump was installed.
"""

len(list(df_train['construction_year'].unique()))

#The top 20 construction_year code by pump count are shown in the table below:
df_cons=df_train.groupby(['construction_year']).count()
df_cons['id'].sort_values(ascending=False).head(20)

"""The summary statistics shown below indicate a total of 54 distinct non-zero construction year values ranging from 1960 through 2013, with 20,709 records lacking a valid value."""

df_const = df_final[df_final['construction_year']>0]

plt.figure(figsize=(10,6)) 
sns.histplot(data=df_const, x="construction_year", hue="status_group",binwidth=1, multiple="stack").set(title='Non-Zero Contruction Year Histogram')

"""Plotting the status of pumps by construction year allows us to conclude that relatively newer pumps are generally more likely to be functional than are relatively older pumps. While this is rather unsurprising from an intuitive perspective, confirmation of such intuition can prove to be useful when crafting a predictive model.

#### District Code

The district_code variable provides an integer coding of the Tanzanian district within which a given pump is located.
"""

len(list(df_train['district_code'].unique()))

"""The summary statistics shown below indicate a total of 20 distinct district codes within the data set, with each record having a valid value."""

#The top 10 district_code code by pump count are shown in the table below:
df_dc=df_train.groupby(['district_code']).count()
df_dc['id'].sort_values(ascending=False).head(10)

#plt.figure(figsize=(10,6)) 
sns.histplot(data=df_final, x="district_code", hue="status_group",binwidth=1,binrange=(0,10), multiple="stack").set(title='District_code Ranging 0-10 Year Histogram')

plt.figure(figsize=(10,6)) 
sns.histplot(data=df_final, x="district_code", hue="status_group",binwidth=1,binrange=(10,90), multiple="stack").set(title='District_code Ranging 10-90 Year Histogram')

"""The district_code variable is yet another geographic label, and as with the others we’ve analyzed (e.g., basin, region, etc.) we see a wide disparity in the percentage of functional pumps, ranging from a low of 17.4% for district 0 to a hight of 83.3% in district 67. Only 9 of the 20 districts exceed the overall 54.3% functional pump metric. Furthermore we see that six districts’ “non functional” pump percentages exceed 60%."""

df_final.groupby(['district_code','region'])['id'].count()

len(list(df_final.groupby(['district_code','region'])['id'].count()))

"""Further analysis reveals that values of the district_code variable are not unique across regions, as can be seen in the table above where district_code values are aggregated by region. In fact, we find a total of 132 region / district_code combinations within the data set

This dependence on the region variable indicates that the district_code variable itself is unlikely to serve as a valid predictor of a pump’s status. As such, the variable appears unlikely to be independently useful for predictive modeling purposes.

#### Public Meeting
"""

len(list(df_train['public_meeting'].unique()))

df_train['public_meeting'].isnull().sum()

df_final['public_meeting'].value_counts()

"""The public_meeting variable is essentially a binary variable with 3,334 instances of the variable’s value being unknown."""

df_final.groupby(['public_meeting','status_group'])['id'].count()

"""The statistics above show that, in general, pumps having a public meeting value of TRUE are more likely to be functional than those that have not.

#### lga

The lga variable provides another Tanzania-specific geographic identifier within which a given pump is located.
"""

len(list(df_train['lga'].unique()))

"""The summary statistics shown below indicate a total of 125 lga values within the data set, with each record having a valid value."""

#The top 10 lga code by pump count are shown in the table below:
df_lga=df_train.groupby(['lga']).count()
df_lga['id'].sort_values(ascending=False).head(10)

plt.figure(figsize=(20,6)) 
plt.xticks(rotation = 90)
sns.histplot(data=df_final, x="lga", hue="status_group", multiple="stack")

"""#### Ward

The ward variable represents the name of the geographic ward within which a given pump is located.
"""

len(list(df_train['ward'].unique()))

"""The summary statistics shown above indicate a total of 2092 distinct ward values within the data set, with each record having a valid value. """

#The top 10 ward code by pump count are shown in the table below:
df_w=df_train.groupby(['ward']).count()
df_w['id'].sort_values(ascending=False).head(10)

"""#### scheme_management

The scheme_management variable represents the type of organization responsible for managing a given pump.
"""

len(list(df_train['scheme_management'].unique()))

df_train['scheme_management'].isnull().sum()

"""The summary statistics shown below indicate a total of 13 distinct scheme management values within the data set, with 3,877 records having no valid value."""

#The top 10 scheme_management code by pump count are shown in the table below:
df_sm=df_train.groupby(['scheme_management']).count()
df_sm['id'].sort_values(ascending=False).head(10)

plt.figure(figsize=(10,6)) 
plt.xticks(rotation = 90)
sns.histplot(data=df_final, x="scheme_management", hue="status_group", multiple="stack")

"""Plots for the scheme_management variable show that (excluding “None” since it applies to only a single pump) that while the Water Board scheme seems to yield the largest percentage of functional pumps, that scheme is used for a relatively small number (2,748) of the 59,400 pumps. By contrast, the VWC scheme is used for nearly 36,800 pumps. So while a majority of the schemes exceed the 54.3% overall functional metric, the vast majority of the pumps themselves do not benefit from those schemes.

#### scheme_name

The scheme_name variable represents the name of the party responsible for managing a given pump.
"""

len(list(df_train['scheme_name'].unique()))

df_train['scheme_name'].isnull().sum()

"""The summary statistics shown below indicate a total of 2,697 distinct scheme name values within the data set, with 28,166 records having no valid value."""

#The top 10 scheme_name code by pump count are shown in the table below:
df_sn=df_train.groupby(['scheme_name']).count()
df_sn['id'].sort_values(ascending=False).head(10)

"""The large percentage of records lacking a defined scheme name combined with the lack of a definitive list of valid scheme names makes it unlikely to be useful for predictive modeling purposes.

#### permit

The permit variable is a binary True/False indicator.
"""

len(list(df_train['permit'].unique()))

df_train['permit'].value_counts()

df_train['permit'].isnull().sum()

df_final.groupby(['permit','status_group'])['id'].count()

"""The stats above show that pumps indicated as having a permit are more likely to be functional than are those that did not require a permit.

#### extraction_type

The extraction_type variable represents the method of extraction used by a given pump.
"""

len(list(df_train['extraction_type'].unique()))

"""The summary statistics shown below indicate a total of 18 distinct extraction_type values within the data set, with each record having a valid value."""

#The top 10 extraction_type code by pump count are shown in the table below:
df_et=df_train.groupby(['extraction_type']).count()
df_et['id'].sort_values(ascending=False).head(10)

plt.figure(figsize=(10,6)) 
plt.xticks(rotation = 90)
sns.histplot(data=df_final, x="extraction_type", hue="status_group", multiple="stack")

"""Plots of the extraction_type variable show that seven of the seventeen extraction types have functional metrics that exceed the overall 54.3% benchmark. Of particular interest here is the gravity type since nearly 27,000 of the 59,400 total pumps rely on that approach, a far higher percentage than any of the other extraction types.

#### extraction_type_group

The extraction_type_group variable represents a composite of the methods of extraction indicated by the extraction_type variable.
"""

len(list(df_train['extraction_type_group'].unique()))

"""The summary statistics shown below indicate a total of 13 distinct extraction_type_group values within the data set, with each record having a valid value."""

plt.figure(figsize=(10,6)) 
plt.xticks(rotation = 90)
sns.histplot(data=df_final, x="extraction_type_group", hue="status_group", multiple="stack")

"""The extraction_type_group indicator appears to represent a narrowing of the breadth of values available via the extraction_type variable into various higher-level overall categories. The gravity type group again accounts for the largest percentage of total pumps.

#### extraction_type_class

The extraction_type_class variable represents a composite of the methods of extraction indicated by the extraction_type_group variable.
"""

len(list(df_train['extraction_type_class'].unique()))

"""The summary statistics shown below indicate a total of 7 distinct extraction_type_class values within the data set, with each record having a valid value."""

plt.figure(figsize=(10,6)) 
plt.xticks(rotation = 90)
sns.histplot(data=df_final, x="extraction_type_class", hue="status_group", multiple="stack")

"""The extraction_type_class indicator appears to represent a narrowing of the breadth of values available via the extraction_type_group variable into various higher-level overall categories. The gravity type class again accounts for the largest percentage of total pumps. However, the handpump class also represents a significant percentage of the total pump count, with nearly 16,400 pumps having been assigned to that class. Of the seven classes, three exceed the 54.3% overall functional benchmark.

#### management

The management variable represents the name of the method employed for management of a given pump.
"""

len(list(df_train['management'].unique()))

"""The summary statistics shown below indicate a total of 12 distinct management values within the data set, with each record having a valid value."""

#The top 10 management code by pump count are shown in the table below:
df_m=df_train.groupby(['management']).count()
df_m['id'].sort_values(ascending=False).head(10)

plt.figure(figsize=(15,6)) 
plt.xticks(rotation = 90)
sns.histplot(data=df_final, x="management", hue="status_group", multiple="stack")

"""VWC dominates the management variable’s values, with more than 40,000 pumps having been assigned that value. As we can see in the plots below, while seven other management approaches have higher percentages of their pumps functional, collectively those seven approaches are applied to less than one third of the pumps.

#### management_group

The management_group variable may represent a composite of the management method names indicated by the management variable.
"""

len(list(df_train['management_group'].unique()))

#The top 10 management_group code by pump count are shown in the table below:
df_mg=df_train.groupby(['management_group']).count()
df_mg['id'].sort_values(ascending=False)

"""The summary statistics shown below indicate a total of 5 distinct management_group values within the data set, including 561 records labeled as “unknown”."""

plt.figure(figsize=(15,6)) 
plt.xticks(rotation = 90)
sns.histplot(data=df_final, x="management_group", hue="status_group", multiple="stack")

"""The management_group variable’s most relevant value is user-group, with 52,490 pumps having been assigned that value. As we can see in the plots, user-group yields a functional pump percentage close to that of the 54.3% overall functional metric.

#### payment

The payment variable represents how the water is actually paid for by users of the pump, if at all.
"""

len(list(df_train['payment'].unique()))

"""The summary statistics shown below indicate a total of 7 distinct payment values within the data set, with each record having a valid value."""

#The top 10 payment code by pump count are shown in the table below:
df_pa=df_train.groupby(['payment']).count()
df_pa['id'].sort_values(ascending=False)

plt.figure(figsize=(10,5)) 
plt.xticks(rotation = 90)
sns.histplot(data=df_final, x="payment", hue="status_group", multiple="stack")

"""As shown above, more than 25,000 pumps require no payment for their use, and, unsurprisingly, as shown in the graphics below, those pumps appear to be the least functional overall if unknown payment types are excluded. However, pumps that do not require payment may be located in remote areas where collection of payment is not feasible. Nevertheless, it appears reasonable to conclude that requiring users to pay for use of a pump is more likely to result in a pump remaining functional than will allowing use of a pump free of charge.

#### payment_type

The payment_type variable represents a duplicate of the payment methods indicated by the payment variable, with the sole difference being that payment’s “pay when scheme fails” category has been replaced by “on failure”.
"""

len(list(df_train['payment_type'].unique()))

"""The summary statistics shown below indicate a total of 7 distinct payment_type values within the data set, with each record having a valid value."""

plt.figure(figsize=(10,5)) 
plt.xticks(rotation = 90)
sns.histplot(data=df_final, x="payment_type", hue="status_group", multiple="stack")

"""The payment_type variable’s values are not distinct from those of the payment variable. In fact, the names of the values are simply minor alterations of those provided via the payment variable. All of the plots shown below exhibit values identical to those of the payment variable once the minor value name alterations are considered. As such, the payment_type variable appears to be redundant and can therefore be ignored for purposes of model building.

#### water_quality

The water_quality variable is an indicator of the quality of the water produced by a given pump.
"""

len(list(df_train['water_quality'].unique()))

"""The summary statistics shown below indicate a total of 8 distinct water_quality values within the data set, with each record having a valid value."""

#The top 10 water_quality by pump count are shown in the table below:
df_w=df_train.groupby(['water_quality']).count()
df_w['id'].sort_values(ascending=False)

plt.figure(figsize=(10,6)) 
plt.xticks(rotation = 90)
sns.histplot(data=df_final, x="water_quality", hue="status_group", multiple="stack")

"""The water_quality variable is dominated by the soft value, with 50,818 of the 59,400 pumps having that water_quality value. While the plots shown below indicate that the largest percentage of functional pumps belong to those of the fluoride category, there are only 200 such pumps throughout the country.

#### quality_group

The quality_group variable represents a composite of the water quality indicators provided by the water_quality variable.
"""

len(list(df_train['quality_group'].unique()))

"""The summary statistics shown below indicate a total of 6 distinct quality_group values within the data set, with each record having a valid value."""

plt.figure(figsize=(10,6)) 
#plt.xticks(rotation = 90)
sns.histplot(data=df_final, x="quality_group", hue="status_group", multiple="stack")

"""The quality_group variable appears to represent a narrowing of the breadth of values available via the water_quality variable. In fact, the number of pumps in the good category is identical to those of the water_quality variable’s soft category, while the fluoride and salty categories have been created by summing the fluoride, fluoride_abandoned, and salty and salty_abandoned categories belonging to the water_quality variable. As such, this variable may be duplicative/redundant and therefore may likely be considered for removal for purposes of model building.

#### Quantity & Quantity_Group

The quantity and quantity_group variables are exact duplicates of one another, as shown in the summary statistics provided below. Both variables are used to indicate the quantity of water available at a given pump.
"""

len(list(df_train['quantity_group'].unique()))

len(list(df_train['quantity'].unique()))

"""The summary statistics indicate a total of 5 distinct quantity and quantity_group values within the data set, with each record having a valid value.

The quantity and quantity_group variables have identical categories with identical numbers of pumps assigned to each. As such, the quantity_group variable is likely to be redundant/duplicative and can therefore be ignored for purposes of model building.
"""

plt.figure(figsize=(10,6)) 
#plt.xticks(rotation = 90)
sns.histplot(data=df_final, x="quantity", hue="status_group", multiple="stack")

"""Of the five quantity categories, the dry category offers the smallest percentage of functional pumps with only 2.5% of such pumps being labeled as such. By contrast, more than 65% of pumps categorized as having a quantity of enough are functional.

#### source

The source variable indicates the source of the water for a given pump.
"""

len(list(df_train['source'].unique()))

"""The summary statistics shown below indicate a total of 10 distinct source values within the data set, with each record having a valid value."""

plt.figure(figsize=(10,6)) 
plt.xticks(rotation = 90)
sns.histplot(data=df_final, x="source", hue="status_group", multiple="stack")

"""As shown above, the spring category of the source variable offers the highest percentage of functional pumps and also represents the largest source category with 17,021 pumps. By contrast, while the lake category performs poorly, it represents only 765 of the 59,400 pumps represented in the data set. Of the other categories represented, 57.8% of source = dam are also not functioning.

#### source_type

The source_type variable appears to be a composite of the source variable.
"""

len(list(df_train['source_type'].unique()))

"""The summary statistics shown below indicate a total of 7 distinct source_type values within the data set, with each record having a valid value.

The source_type variable appears to combine some of the categories from source variable. As such, this variable may be redundant / duplicative and might possibly be ignored for purposes of model building.
"""

plt.figure(figsize=(10,6)) 
plt.xticks(rotation = 90)
sns.histplot(data=df_final, x="source_type", hue="status_group", multiple="stack")

"""As shown above, the spring category of the source_type variable offers the highest percentage of functional pumps and also represents the largest source_type category with 17,021 pumps. By contrast, while the dam category performs poorly, it represents only 656 of the 59,400 pumps represented in the data set. Of the other categories represented, 46.2% of source_type = borehole are also not functioning.

#### source_class

The source_class variable appears to be a composite of the source_type variable.
"""

len(list(df_train['source_class'].unique()))

"""The summary statistics shown below indicate a total of 3 distinct source_class values within the data set, with each record having a valid value."""

#The top 10 source_class by pump count are shown in the table below:
df_sc=df_train.groupby(['source_class']).count()
df_sc['id'].sort_values(ascending=False)

plt.figure(figsize=(6,6)) 
plt.xticks(rotation = 90)
sns.histplot(data=df_final, x="source_class", hue="status_group", multiple="stack")

"""The source_class variable appears to be a binary indicator, with, as shown below, both known categories appearing to be equally likely to offer a functional pump. However, groundwater class pumps appear to be more likely than surface class pumps to be completely non-functional.

#### waterpoint_type

The waterpoint_type variable indicates the type of pump installed at a given location.
"""

len(list(df_train['waterpoint_type'].unique()))

"""The summary statistics shown below indicate a total of 7 distinct waterpoint_type values within the data set, with each record having a valid value."""

#The top 10 waterpoint_type by pump count are shown in the table below:
df_wt=df_train.groupby(['waterpoint_type']).count()
df_wt['id'].sort_values(ascending=False)

plt.figure(figsize=(6,6)) 
plt.xticks(rotation = 90)
sns.histplot(data=df_final, x="waterpoint_type", hue="status_group", multiple="stack")

"""As shown above, the waterpoint_type variable’s values indicate that pumps having a dam as their waterpoint are the most likely to be functional while communal standpipe multiple appear to be the least likely to be functional. However, there are only 7 pumps having a waterpoint_type of dam. In fact, the most common waterpoint_type is communal standpipe followed by hand pump. Both of those categories appear to perform well relative to the overall functional benchmark of 54.3%.

#### waterpoint_type_group

The waterpoint_type_group variable appears to be a composite of the waterpoint_type variable.
"""

len(list(df_train['waterpoint_type_group'].unique()))

"""The summary statistics shown below indicate a total of 6 distinct waterpoint_type_group values within the data set, with each record having a valid value."""

plt.figure(figsize=(6,6)) 
plt.xticks(rotation = 90)
sns.histplot(data=df_final, x="waterpoint_type_group", hue="status_group", multiple="stack")

"""As shown above, the waterpoint_type_group appears to be a composite of the waterpoint_type variable, with the sole difference being the two standpipe groups have been summed together. As such, this variable is likely duplicative / redundant and might possibly be ignored for purposes of model building. Plots showing the status of pumps by waterpoint_type_group value are shown below.

# Initial Predictive Preferences (Arrived on using EDA)

The barplots shown above allow us to gain insight into some of the the predictive aspects of the data. The plots show that most of the **categorical variables** do, in fact, contain **significant predictive characteristics**. For example, we find **geographic variability** with respect to the functional status of pumps via variables such as **basin** and **region**.

**Additional variability** in the functional status of pumps can be found via variables such as **scheme_management**, **construction_year**, **public_meeting**, **extraction_type**, **management**, **payment**, **source**, **quantity**, **water_quality**, and **waterpoint_type**.

Plots for the **numeric variables** show that **gps_height**, **longitude**, and **latitude** also **contain predictive characteristics**, while **population** and **amount_tsh** appear likely to have **less predictive value**.

This variability is indicative of the predictive value of the variables. 

For example- 
1. Pumps located within the Lake Nyasa basin are far more likely to be functional than are pumps located within the Southern Coast basin (65.4% vs 37.2%). 
2. Relatively newer pumps are more likely to be functional than are relatively older pumps (see plot for construction_year). 
3. Furthermore, pumps located in the Arusha region are more than twice as likely to be functional than are pumps found within the region of Lindi (68.5% vs 29.8%). 
4. Pumps that require some form of payment for use are much more likely to be functional than are pumps that require no payment (see plot for payment). 

Similar types of inferences can be postulated relative to the functional needs repair and non functional statuses.

Such inferences are helpful for purposes of model building since they suggest that many variables/combination of variables found within the data set are strong candidates for inclusion within a prospective predictive / classification model.

# Data Cleaning And Preparation

## Data Reading and Merging
"""

#Importing the Data Sets

## Importing the Training set values
train_data = pd.read_csv('Training Set.csv')

## Importing Class labels 
train_labels = pd.read_csv('Training Set Labels.csv')

## Importing the Testing set values for validating the trained model
test_df = pd.read_csv('Test Set.csv')

#Combining the training_values and training_lables
training_df = pd.merge(train_data, train_labels)

"""## Dropping The Features With Similarity

The group of features - 
1. extraction_type, extraction_type_group, extraction_type_class
2. payment, payment_type
3. water_quality, quality_group
4. source, source_class
5. subvillage, region, region_code, district_code, lga, ward 
6. waterpoint_type, waterpoint_type_group 

Above all feature groups contain similar representation of data in different grains. Hence, we risk overfitting our data during training by including all the features in our analysis.

- id can be dropped because it is unique for each instance. we can't derive much predictive variability from it.
- num_private is approx 99% zeros.
"""

training_df = training_df.drop(['id','source','wpt_name', 'num_private','district_code','region_code', 
          'quantity','quality_group','lga','ward','management', 'payment', 
           'extraction_type_group','extraction_type_class','waterpoint_type_group'],axis = 1)

training_df.recorded_by.value_counts()

"""Looks like every record is recorded by GeoData and it dosen't influence more on our model so we can drop it."""

training_df= training_df.drop('recorded_by', axis=1)

training_df.shape

"""Looking at the data, some of the features that seemed discriminative based on human intuition. amount_tsh (amount of water available to water point), gps_height, basin, installer, population, scheme_management, construction year, extraction_type, management_group, water_quality, payment type, source, and waterpoint_type seemed like they could be extremely important in identifying the pump status.

## Dealing with Null / Zero Values

There are null values in our features which are needeed to be updated for better training.

### Categorical Variables

For features with high arity, let us keep the top 10 values, based on frequency and assign all the remaining values to 11th synthetic value as “others”.

#### funder
"""

training_df.funder.value_counts().head(10)

def funder_cl(row):
    '''Keepig most frequent feature value for funder and assining other to non-frequent feature value'''
    
    if row['funder']=='Government Of Tanzania':
        return 'gov'
    elif row['funder']=='Danida':
        return 'danida'
    elif row['funder']=='Hesawa':
        return 'hesawa'
    elif row['funder']=='Rwssp':
        return 'rwssp'
    elif row['funder']=='World Bank':
        return 'world_bank'    
    elif row['funder']=='Kkkt':
        return 'Kkkt'
    elif row['funder']=='World Vision':
        return 'World Vision'
    elif row['funder']=='Unicef':
        return 'Unicef'
    elif row['funder']=='Tasaf':
        return 'Tasaf'
    elif row['funder']=='District Council':
        return 'District Council'
    else:
        return 'other'

training_df['funder'] = training_df.apply(lambda row: funder_cl(row), axis=1)

training_df['funder'].value_counts()

plt.figure(figsize=(8,8)) 
plt.xticks(rotation = 90)
sns.histplot(data=training_df, x="funder", hue="status_group", multiple="stack")

"""#### Installer"""

training_df.installer.value_counts().head(10)

def installer_cl(row):

    '''Keepig most frequent feature value for installer and assining other to non-frequent feature value'''
    
    if row['installer']=='DWE':
        return 'dwe'
    elif row['installer']=='Government':
        return 'gov'
    elif row['installer']=='RWE':
        return 'rwe'
    elif row['installer']=='Commu':
        return 'commu'
    elif row['installer']=='DANIDA':
        return 'danida'
    elif row['installer']=='KKKT':
        return 'kkkt'
    elif row['installer']=='Hesawa':
        return 'hesawa'
    elif row['installer']=='TCRS':
        return 'tcrs'
    elif row['installer']=='Central government':
        return 'Central government'
    else:
        return 'other'

training_df['installer'] = training_df.apply(lambda row: installer_cl(row), axis=1)

training_df['installer'].value_counts()

plt.figure(figsize=(8,8)) 
plt.xticks(rotation = 90)
sns.histplot(data=training_df, x="installer", hue="status_group", multiple="stack")

"""#### subvillage

Fill the remaining instances with 'other'.
"""

training_df.subvillage = training_df.subvillage.fillna('other')

training_df.subvillage.value_counts()

"""#### public_meeting"""

training_df.public_meeting.value_counts()

"""There are only two values in this column so, we can keep it and fill the null values to Unknown."""

training_df.public_meeting = training_df.public_meeting.fillna('Unknown')

"""####  scheme_management"""

training_df.scheme_management.value_counts()

def scheme_cl(row):

    '''Keepig most frequent feature value for scheme_management and assining other to non-frequent feature value'''

    if row['scheme_management']=='VWC':
        return 'vwc'
    elif row['scheme_management']=='WUG':
        return 'wug'
    elif row['scheme_management']=='Water authority':
        return 'wtr_auth'
    elif row['scheme_management']=='WUA':
        return 'wua'
    elif row['scheme_management']=='Water Board':
        return 'wtr_brd'
    elif row['scheme_management']=='Parastatal':
        return 'Parastatal'
    elif row['scheme_management']=='Private operator':
        return 'pri_optr'
    elif row['scheme_management']=='SWC':
        return 'swc'
    elif row['scheme_management']=='Company':
        return 'company'
    elif row['scheme_management']=='Trust':
        return 'trust'
    else:
        return 'other'

training_df['scheme_management'] = training_df.apply(lambda row: scheme_cl(row), axis=1)

training_df.scheme_management.value_counts()

"""#### scheme_name"""

training_df.scheme_name = training_df.scheme_name.fillna('other')

"""#### permit"""

training_df.permit = training_df.permit.fillna('Unknown')

"""#### construction_year"""

## changing the construction year to numeric value
training_df.construction_year = pd.to_numeric(training_df.construction_year)

def construction_cl(row):

    '''Converting the datatime into categorical as in : '60s', '70s', '80s', '90s, 
    '00s', '10s', 'unknown' which dosent have any year value for our convinience'''

    if row['construction_year'] >= 1960 and row['construction_year'] < 1970:
        return '60s'
    elif row['construction_year'] >= 1970 and row['construction_year'] < 1980:
        return '70s'
    elif row['construction_year'] >= 1980 and row['construction_year'] < 1990:
        return '80s'
    elif row['construction_year'] >= 1990 and row['construction_year'] < 2000:
        return '90s'
    elif row['construction_year'] >= 2000 and row['construction_year'] < 2010:
        return '00s'
    elif row['construction_year'] >= 2010:
        return '10s'
    else:
        return 'unknown'

training_df['construction_year'] = training_df.apply(lambda row: construction_cl(row), axis=1)

"""##### Cheking for Any further Null Values


"""

# Cheking for any further null values left
training_df.apply(lambda x: sum(x.isnull()))

"""#### extraction_type"""

training_df.extraction_type.value_counts()

def extraction_cl(row):

    '''Keepig most frequent feature value for extraction_type and assining other to non-frequent feature value'''

    if row['extraction_type']=='gravity':
        return 'gravity'
    elif row['extraction_type']=='nira/tanira':
        return 'nira'
    elif row['extraction_type']=='submersible':
        return 'submersible'
    elif row['extraction_type']=='swn 80':
        return 'swn'
    elif row['extraction_type']=='mono':
        return 'mono'
    elif row['extraction_type']=='india mark ii':
        return 'indiamark2'
    elif row['extraction_type']=='afridev':
        return 'afridev'
    elif row['extraction_type']=='ksb':
        return 'ksb'
    elif row['extraction_type']=='windmill':
        return 'windmill'
    elif row['extraction_type']=='india mark iii':
        return 'indiamark3'
    else:
        return 'other'

training_df['extraction_type'] = training_df.apply(lambda row: extraction_cl(row), axis=1)

"""### Numerical Variables

#### Adding New Feature

##### days_since_recorded
"""

# converting date_recorded to datetime format
training_df.date_recorded = pd.to_datetime(training_df.date_recorded)
training_df.date_recorded.describe()

"""Add a new column/feature named days_since_recorded (which is obtained from subratcting date_recorded from latest recorded date) so that we get a new column which contains no. of days since recorded. The most recent data is 2013-12-03. Subtract each date from this point to obtain a 'days_since_recorded' column."""

training_df.date_recorded = pd.datetime(2013, 12, 3) - pd.to_datetime(training_df.date_recorded)
training_df.columns = ['days_since_recorded' if x=='date_recorded' else x for x in training_df.columns]
training_df.days_since_recorded = training_df.days_since_recorded.astype('timedelta64[D]').astype(int)
training_df.days_since_recorded.describe()

plt.figure(figsize=(8,8)) 
plt.xticks(rotation = 90)
sns.histplot(data=training_df, x="days_since_recorded", hue="status_group",binrange=(0,1500), multiple="stack")

"""#### Longitude & Latitdue

Replacing with mean values for 1812 such instances of longitude = 0 and latitude > -1
"""

training_df['longitude'] = training_df['longitude'].map( lambda x : training_df.longitude.mean() if x == 0 else x)

training_df['latitude'] = training_df['latitude'].map( lambda x : training_df.latitude.mean() if x > -1 else x)

"""# Performing Data Processing on Test Set"""

test_df = test_df.drop(['id','source','wpt_name', 'num_private','district_code','region_code', 
          'quantity','quality_group','lga','ward','management', 'payment', 
           'extraction_type_group','extraction_type_class','waterpoint_type_group'],axis = 1)

test_df['funder'] = test_df.apply(lambda row: funder_cl(row), axis=1)

test_df['installer'] = test_df.apply(lambda row: installer_cl(row), axis=1)

test_df.subvillage = test_df.subvillage.fillna('other')

test_df.public_meeting = test_df.public_meeting.fillna('Unknown')

test_df['scheme_management'] = test_df.apply(lambda row: scheme_cl(row), axis=1)

test_df.scheme_name = test_df.scheme_name.fillna('other')

test_df.permit = test_df.permit.fillna('Unknown')

test_df['construction_year'] = test_df.apply(lambda row: construction_cl(row), axis=1)

test_df['extraction_type'] = test_df.apply(lambda row: extraction_cl(row), axis=1)

test_df.date_recorded = pd.to_datetime(test_df.date_recorded)
test_df.date_recorded.describe()

test_df.date_recorded = pd.datetime(2013, 12, 3) - pd.to_datetime(test_df.date_recorded)
test_df.columns = ['days_since_recorded' if x=='date_recorded' else x for x in test_df.columns]
test_df.days_since_recorded = test_df.days_since_recorded.astype('timedelta64[D]').astype(int)
test_df.days_since_recorded.describe()

test_df['longitude'] = test_df['longitude'].map( lambda x : test_df.longitude.mean() if x == 0 else x)

test_df['latitude'] = test_df['latitude'].map( lambda x : test_df.latitude.mean() if x > -1 else x)

test_df= test_df.drop('recorded_by', axis=1)

"""# Checking Final Processed Train and Test Set Features"""

training_df.shape

test_df.shape

training_df.head()

test_df.head()

"""# Final Set of Features """

list(test_df.columns)

"""# Exporting the datasets for Modeling"""

training_df.to_csv('training_data.csv', index=True)

test_df.to_csv('test_data.csv', index=True)